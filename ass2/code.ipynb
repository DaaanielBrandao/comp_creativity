{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'nltk'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2388/2529474298.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mstring\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmarkovify\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchain\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mChain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBEGIN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEND\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmarkovify\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'nltk'"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import glob\n",
    "import re\n",
    "import string\n",
    "import nltk\n",
    "from markovify.chain import Chain\n",
    "import markovify.text\n",
    "#import spacy\n",
    "import markovify\n",
    "import markovify.text\n",
    "\n",
    "#nlp = spacy.load(\"en_core_web_sm\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "This part of the code is responsible to combine all different poems of a certain theme into one common file, so that\n",
    "it can be later use to feed our model.\n",
    "'''\n",
    "\n",
    "def glob_re(pattern, strings):\n",
    "    return filter(re.compile(pattern).match, strings)\n",
    "\n",
    "nature_themes = \"(nature|spring|water|weather|rose)\"\n",
    "depression_themes = \"(suicide|sorrow)\"\n",
    "\n",
    "res = [f for f in glob.glob('./sample corpus/topics/**/*.txt') if re.search( depression_themes + '*.txt$', f)]\n",
    "\n",
    "    \n",
    "with open('combined.txt', 'w',encoding=\"utf-8\") as outfile:\n",
    "    for fname in res:\n",
    "        with open(fname,encoding=\"utf-8\") as infile:\n",
    "            for line in infile:\n",
    "                outfile.write(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "'''\n",
    "This function calculates the number of syllables present in a line. This function was copied based on english rules and\n",
    "it can be find in the following website: https://eayd.in/?p=232\n",
    "'''\n",
    "def sylco(word) :\n",
    "\n",
    "    word = word.lower()\n",
    "\n",
    "    # exception_add are words that need extra syllables\n",
    "    # exception_del are words that need less syllables\n",
    "\n",
    "    exception_add = ['serious','crucial']\n",
    "    exception_del = ['fortunately','unfortunately']\n",
    "\n",
    "    co_one = ['cool','coach','coat','coal','count','coin','coarse','coup','coif','cook','coign','coiffe','coof','court']\n",
    "    co_two = ['coapt','coed','coinci']\n",
    "\n",
    "    pre_one = ['preach']\n",
    "\n",
    "    syls = 0 #added syllable number\n",
    "    disc = 0 #discarded syllable number\n",
    "\n",
    "    #1) if letters < 3 : return 1\n",
    "    if len(word) <= 3 :\n",
    "        syls = 1\n",
    "        return syls\n",
    "\n",
    "    #2) if doesn't end with \"ted\" or \"tes\" or \"ses\" or \"ied\" or \"ies\", discard \"es\" and \"ed\" at the end.\n",
    "    # if it has only 1 vowel or 1 set of consecutive vowels, discard. (like \"speed\", \"fled\" etc.)\n",
    "\n",
    "    if word[-2:] == \"es\" or word[-2:] == \"ed\" :\n",
    "        doubleAndtripple_1 = len(re.findall(r'[eaoui][eaoui]',word))\n",
    "        if doubleAndtripple_1 > 1 or len(re.findall(r'[eaoui][^eaoui]',word)) > 1 :\n",
    "            if word[-3:] == \"ted\" or word[-3:] == \"tes\" or word[-3:] == \"ses\" or word[-3:] == \"ied\" or word[-3:] == \"ies\" :\n",
    "                pass\n",
    "            else :\n",
    "                disc+=1\n",
    "\n",
    "    #3) discard trailing \"e\", except where ending is \"le\"  \n",
    "\n",
    "    le_except = ['whole','mobile','pole','male','female','hale','pale','tale','sale','aisle','whale','while']\n",
    "\n",
    "    if word[-1:] == \"e\" :\n",
    "        if word[-2:] == \"le\" and word not in le_except :\n",
    "            pass\n",
    "\n",
    "        else :\n",
    "            disc+=1\n",
    "\n",
    "    #4) check if consecutive vowels exists, triplets or pairs, count them as one.\n",
    "\n",
    "    doubleAndtripple = len(re.findall(r'[eaoui][eaoui]',word))\n",
    "    tripple = len(re.findall(r'[eaoui][eaoui][eaoui]',word))\n",
    "    disc+=doubleAndtripple + tripple\n",
    "\n",
    "    #5) count remaining vowels in word.\n",
    "    numVowels = len(re.findall(r'[eaoui]',word))\n",
    "\n",
    "    #6) add one if starts with \"mc\"\n",
    "    if word[:2] == \"mc\" :\n",
    "        syls+=1\n",
    "\n",
    "    #7) add one if ends with \"y\" but is not surrouned by vowel\n",
    "    if word[-1:] == \"y\" and word[-2] not in \"aeoui\" :\n",
    "        syls +=1\n",
    "\n",
    "    #8) add one if \"y\" is surrounded by non-vowels and is not in the last word.\n",
    "\n",
    "    for i,j in enumerate(word) :\n",
    "        if j == \"y\" :\n",
    "            if (i != 0) and (i != len(word)-1) :\n",
    "                if word[i-1] not in \"aeoui\" and word[i+1] not in \"aeoui\" :\n",
    "                    syls+=1\n",
    "\n",
    "    #9) if starts with \"tri-\" or \"bi-\" and is followed by a vowel, add one.\n",
    "\n",
    "    if word[:3] == \"tri\" and word[3] in \"aeoui\" :\n",
    "        syls+=1\n",
    "\n",
    "    if word[:2] == \"bi\" and word[2] in \"aeoui\" :\n",
    "        syls+=1\n",
    "\n",
    "    #10) if ends with \"-ian\", should be counted as two syllables, except for \"-tian\" and \"-cian\"\n",
    "\n",
    "    if word[-3:] == \"ian\" : \n",
    "    #and (word[-4:] != \"cian\" or word[-4:] != \"tian\") :\n",
    "        if word[-4:] == \"cian\" or word[-4:] == \"tian\" :\n",
    "            pass\n",
    "        else :\n",
    "            syls+=1\n",
    "\n",
    "    #11) if starts with \"co-\" and is followed by a vowel, check if exists in the double syllable dictionary, if not, check if in single dictionary and act accordingly.\n",
    "\n",
    "    if word[:2] == \"co\" and word[2] in 'eaoui' :\n",
    "\n",
    "        if word[:4] in co_two or word[:5] in co_two or word[:6] in co_two :\n",
    "            syls+=1\n",
    "        elif word[:4] in co_one or word[:5] in co_one or word[:6] in co_one :\n",
    "            pass\n",
    "        else :\n",
    "            syls+=1\n",
    "\n",
    "    #12) if starts with \"pre-\" and is followed by a vowel, check if exists in the double syllable dictionary, if not, check if in single dictionary and act accordingly.\n",
    "\n",
    "    if word[:3] == \"pre\" and word[3] in 'eaoui' :\n",
    "        if word[:6] in pre_one :\n",
    "            pass\n",
    "        else :\n",
    "            syls+=1\n",
    "\n",
    "    #13) check for \"-n't\" and cross match with dictionary to add syllable.\n",
    "\n",
    "    negative = [\"doesn't\", \"isn't\", \"shouldn't\", \"couldn't\",\"wouldn't\"]\n",
    "\n",
    "    if word[-3:] == \"n't\" :\n",
    "        if word in negative :\n",
    "            syls+=1\n",
    "        else :\n",
    "            pass   \n",
    "\n",
    "    #14) Handling the exceptional words.\n",
    "\n",
    "    if word in exception_del :\n",
    "        disc+=1\n",
    "\n",
    "    if word in exception_add :\n",
    "        syls+=1     \n",
    "\n",
    "    # calculate the output\n",
    "    return numVowels - disc + syls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Utility function for text cleaning\n",
    "'''\n",
    "def text_cleaner(text):\n",
    "  text = re.sub(r'--', ' ', text)\n",
    "  text = re.sub('[\\[].*?[\\]]', '', text)\n",
    "  text = re.sub(r'(\\b|\\s+\\-?|^\\-?)(\\d+|\\d*\\.\\d+)\\b','', text)\n",
    "  text = ' '.join(text.split())\n",
    "  return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Writes each line of the compiled poems in a reversed-word order so that we\n",
    "are able to create a reverse markov model\n",
    "'''\n",
    "with open('./combined.txt',encoding=\"utf-8\") as f:\n",
    "    with open(\"./result.txt\", \"w\",encoding=\"utf-8\") as output:\n",
    "        lines = f.readlines()\n",
    "        for sentence in lines:\n",
    "            sentence = sentence[:-1]\n",
    "            sentence = text_cleaner(sentence)\n",
    "            words = sentence.split(' ') \n",
    "\n",
    "            for i in range(len(words)):\n",
    "                words[i] = words[i].lower().strip(\".:;?!,\")\n",
    "                words[i].translate(str.maketrans('', '', string.punctuation))\n",
    "\n",
    "            reverse_sentence = ' '.join(reversed(words)) + \"\\n\"\n",
    "            output.write(reverse_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Using nlk, get words that rhyme with the input*\n",
    "'''\n",
    "def get_rhyming_words(input, order):\n",
    "    pronunDict = dict(nltk.corpus.cmudict.entries())\n",
    "    rhyme_list = []\n",
    "\n",
    "    inputSyllables = pronunDict.get(input)\n",
    "\n",
    "    if inputSyllables:\n",
    "        rhyme_list += [word for word, pronun in pronunDict.items() if pronun[-order:] == inputSyllables[-order:] and word != input]\n",
    "        return rhyme_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "DEFAULT_TRIES = 10000 # constant of the number of tries to do to find a type of phrase we are looking for\n",
    "\n",
    "'''\n",
    " Extending the class NewLineText (since we consider that each line should be considered independently as\n",
    " we found that pontuaction is absent quite frequently)\n",
    "'''\n",
    "class rhymeText(markovify.NewlineText):\n",
    "\n",
    "    '''\n",
    "    # if we want to use spacy (takes way longer):\n",
    "    def word_split(self, sentence):\n",
    "        return [\"::\".join((word.orth_, word.pos_)) for word in nlp(sentence)]\n",
    "\n",
    "    def word_join(self, words):\n",
    "        sentence = \" \".join(word.split(\"::\")[0] for word in words)\n",
    "        return sentence\n",
    "    '''\n",
    "    \n",
    "    '''\n",
    "        Constructor adapted from the documentation and source code\n",
    "    '''\n",
    "    def __init__(self, input_text, state_size=1, chain=None, parsed_sentences=None, retain_original=True):\n",
    "\n",
    "\n",
    "        super().__init__(input_text)\n",
    "        can_make_sentences = parsed_sentences is not None or input_text is not None\n",
    "        self.retain_original = retain_original and can_make_sentences\n",
    "        self.state_size = state_size\n",
    "        self.rhyme_word = \"\"\n",
    "\n",
    "        if self.retain_original:\n",
    "            self.parsed_sentences = list(self.generate_corpus(input_text))\n",
    "\n",
    "            self.rejoined_text = self.sentence_join(map(self.word_join, self.parsed_sentences))\n",
    "\n",
    "            self.chain = chain or Chain(self.parsed_sentences, state_size)\n",
    "        else:\n",
    "            if not chain:\n",
    "                parsed = parsed_sentences or self.generate_corpus(input_text)\n",
    "            self.chain = chain or Chain(parsed, state_size)\n",
    "\n",
    "\n",
    "    '''\n",
    "        Tries to find a number of rhyme_words in the chain model, also\n",
    "        adapted from the documentation and source code\n",
    "    '''\n",
    "    def choose_word(self, rhyme_word, matchedWord=None, number=1):\n",
    "        total = set([]) # set because we do not want repeated ones\n",
    "\n",
    "        rhyme_list = get_rhyming_words(rhyme_word, 2)\n",
    "\n",
    "        if rhyme_list is None or len(rhyme_list) == 0 or rhyme_list[0] == None:\n",
    "            return None\n",
    "\n",
    "\n",
    "        for word in rhyme_list:\n",
    "            if len(total) >= number:\n",
    "                break\n",
    "            formatted_word = (word,)\n",
    "            formatted_word_ponctuation = (word + '.',) # some may have this in the end\n",
    "\n",
    "            if formatted_word in self.chain.model:\n",
    "                matchedWord = formatted_word\n",
    "                total.add(matchedWord)\n",
    "\n",
    "            elif formatted_word_ponctuation in self.chain.model:\n",
    "                matchedWord = formatted_word_ponctuation\n",
    "                total.add(matchedWord)\n",
    "\n",
    "        \n",
    "        if len(total) < number:\n",
    "            return None\n",
    "        return list(total)\n",
    "\n",
    "\n",
    "    '''\n",
    "        Generates a sentence with a word that rhymes with rhyme_word and that as a number of syllables\n",
    "        between min_syllables and max_syllables. The number if the number of sentences it generates\n",
    "    '''\n",
    "    def make_short_sentence(self, max_syllables, rhyme_word='', min_syllables=10, number=1 ):\n",
    "        tries =  DEFAULT_TRIES\n",
    "\n",
    "        init_state = self.choose_word(rhyme_word, number = number) #4) <===== check this out better\n",
    "        if init_state == None:\n",
    "            return None\n",
    "        \n",
    "        values = []\n",
    "        for x in init_state:\n",
    "            for _ in range(tries):\n",
    "                sentence = self.make_sentence(init_state=x)\n",
    "                if sentence and sylco(sentence) <= max_syllables and sylco(sentence) >= min_syllables:\n",
    "                    values.append(sentence)\n",
    "                    break\n",
    "        \n",
    "        return values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "'''\n",
    "Formats a phrase by putting a uppercase letter in the begining\n",
    "of the verse\n",
    "'''\n",
    "def verse_to_uppercase(sentence):\n",
    "    return sentence[0].upper() + sentence[1:]\n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    " Since the sentence was generated using the reverse markov chain,\n",
    " it reverses the verse and also formats it\n",
    "'''\n",
    "def format_reverse_verse(sentence):\n",
    "    rev = ' '.join(sentence.split()[::-1])\n",
    "    rhyme = (' ').join(rev.split()[1:])\n",
    "    return verse_to_uppercase(rhyme)\n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    "    Builds a normal markov chain model (using the file with combined poems) \n",
    "    and a reverse model (that uses as the input the file that has the verses\n",
    "    reversed)\n",
    "'''\n",
    "def build_markov_model(forward_file, reverse_file):\n",
    "\n",
    "    with open(forward_file,encoding=\"utf-8\") as f:\n",
    "        forward_text = f.read()\n",
    "\n",
    "    with open(reverse_file,encoding=\"utf-8\") as r:\n",
    "        reverse_text = r.read()\n",
    "\n",
    "    forward_model = markovify.NewlineText(forward_text)\n",
    "    reverse_model = rhymeText(reverse_text)\n",
    "\n",
    "    return (forward_model, reverse_model)\n",
    "\n",
    "\n",
    "'''\n",
    "    Gets <size> verses that rhyme with each other\n",
    "'''       \n",
    "def build_rhymes(forward_model, reverse_model, min_syllables = 10, max_syllables=50, size = 1):\n",
    "\n",
    "    A_list = []\n",
    "    while len(A_list) != size:\n",
    "        A_list.clear()\n",
    "\n",
    "        while True:\n",
    "            A = forward_model.make_short_sentence(40, min_syllables=min_syllables) # A\n",
    "            if A != None:\n",
    "                break\n",
    "        \n",
    "        rhyme_word = A.split()[-1]\n",
    "        A_list = []\n",
    "        X = reverse_model.make_short_sentence(max_syllables, rhyme_word, min_syllables=min_syllables, number=size) #3\n",
    "        if X != None and len(X) > 0 and X[0] != None:\n",
    "            A_list = X\n",
    "\n",
    "    result = [verse_to_uppercase(A)]\n",
    "    for x in A_list:\n",
    "        result.append(format_reverse_verse(x))\n",
    "\n",
    "    return result\n",
    "\n",
    "'''\n",
    "    Generates a <size> number of verses that start with a\n",
    "    certain letter\n",
    "'''\n",
    "def build_letter_verse(forward_model, reverse_model, size, letter=None):\n",
    "\n",
    "    A_list = []\n",
    "    while len(A_list) != size:\n",
    "\n",
    "        while True:\n",
    "            A = forward_model.make_short_sentence(55) # A\n",
    "            if A != None and A.startswith(letter):\n",
    "                break\n",
    "        \n",
    "        A_list.append(verse_to_uppercase(A))\n",
    "\n",
    "\n",
    "   \n",
    "    return A_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    Builds a sonnet based on the following metric:\n",
    "    ABBA ABBA CDE CDE\n",
    "'''\n",
    "def sonnet(): # ABBA ABBA CDE CDE\n",
    "    forward_model, reverse_model = build_markov_model(\"./combined.txt\", \"./result.txt\")\n",
    "\n",
    "    A = build_rhymes(forward_model, reverse_model, size=4)\n",
    "    B = build_rhymes(forward_model, reverse_model, size=4)\n",
    "    C = build_rhymes(forward_model, reverse_model, size=2)\n",
    "    D = build_rhymes(forward_model, reverse_model, size=2)\n",
    "    E = build_rhymes(forward_model, reverse_model, size=2)\n",
    "\n",
    "\n",
    "    ans =  [\n",
    "        A[0],\n",
    "        B[0],\n",
    "        B[1],\n",
    "        A[1],\n",
    "        \"\\n\",\n",
    "        A[2],\n",
    "        B[2],\n",
    "        B[3],\n",
    "        A[3],\n",
    "        \"\\n\",\n",
    "        C[0],\n",
    "        D[0],\n",
    "        E[0],\n",
    "        \"\\n\",\n",
    "        C[1],\n",
    "        D[1],\n",
    "        E[1],\n",
    "\n",
    "    ]\n",
    "\n",
    "    return '\\n'.join(ans)\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Straight began to draw correct inference\n",
      "Into the business career\n",
      "To me of dull till the twilight travel and heart was seen the water beer\n",
      "Gallons of something nothing to daylight of the absence\n",
      "\n",
      "\n",
      "Beautiful through the quiet corner of work in one's self acceptance\n",
      "Spiritual prosperity & they start to the world's hunks of the living and we'll give you get more austere\n",
      "Don't think not anymore what does appear\n",
      "Wonder how wide treasure and in the abundance\n",
      "\n",
      "\n",
      "Now, tell me your sword and squire\n",
      "And, deep in red and I am able to fly\n",
      "Of the test is\n",
      "\n",
      "\n",
      "Of the rose is designed to admire\n",
      "It’s my world world world i wish them that bound you will hold you apply\n",
      "Two of his substance abuses\n"
     ]
    }
   ],
   "source": [
    "ans = sonnet()\n",
    "print(ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    Builds an acrostic: this type of poem does not need to rhyme. The interesting\n",
    "    thing about it is that combining the first letter of each verse it should create\n",
    "    a word\n",
    "'''\n",
    "def acrostic(word):\n",
    "    forward_model, reverse_model = build_markov_model(\"./combined.txt\", \"./result.txt\")\n",
    "\n",
    "    ans = []\n",
    "    for s in word:\n",
    "        ans = ans + build_letter_verse(forward_model, reverse_model, size=1 , letter=s)\n",
    "\n",
    "    return '\\n'.join(ans)\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rose to His feet.\n",
      "Or am I within a day\n",
      "So often I taste your infantine toes\n",
      "Even when I can't remember if she makes it possible\n"
     ]
    }
   ],
   "source": [
    "ans = acrostic('rose')\n",
    "print(ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    Builds a limerick based only on the structure it has (not based on its typical theme)\n",
    "    The poem structure is AABBA and the A verses should be longer than the B verses\n",
    "'''\n",
    "def limerick(): # AABBA\n",
    "    forward_model, reverse_model = build_markov_model(\"./combined.txt\", \"./result.txt\")\n",
    "\n",
    "    A = build_rhymes(forward_model, reverse_model, min_syllables= 25, max_syllables=30, size=4)\n",
    "    B = build_rhymes(forward_model, reverse_model, min_syllables= 10, max_syllables= 15, size=2)\n",
    "\n",
    "    ans =  [\n",
    "        A[1],\n",
    "        A[2],\n",
    "        B[0],\n",
    "        B[1],\n",
    "        A[3]\n",
    "    ]\n",
    "\n",
    "    return '\\n'.join(ans)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pulls out of the coming to the sea gods kept feeling the medicines administered\n",
      "Say crack on the gentle ripples as you bring back the stage of horn and flowed like the water was acquired\n",
      "But i need sleep\n",
      "Picnic by pomp and it just the fallen asleep\n",
      "Never actually fighting of kindness and the next year be short of love and i'll be admired\n"
     ]
    }
   ],
   "source": [
    "print(limerick())"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.9.2 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
