{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Todo:\n",
    "* Incorporate with Rita\n",
    "* Generate name of the guy\n",
    "* Template for the bibliography"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "def plotWordFrequency(input):\n",
    "    f = open(artist_file,'r')\n",
    "    words = [x for y in [l.split() for l in f.readlines()] for x in y]\n",
    "    data = sorted([(w, words.count(w)) for w in set(words)], key = lambda x:x[1], reverse=True)[:40] \n",
    "    most_words = [x[0] for x in data]\n",
    "    times_used = [int(x[1]) for x in data]\n",
    "    plt.figure(figsize=(20,10))\n",
    "    plt.bar(x=sorted(most_words), height=times_used, color = 'grey', edgecolor = 'black',  width=.5)\n",
    "    plt.xticks(rotation=45, fontsize=18)\n",
    "    plt.yticks(rotation=0, fontsize=18)\n",
    "    plt.xlabel('Most Common Words:', fontsize=18)\n",
    "    plt.ylabel('Number of Occurences:', fontsize=18)\n",
    "    plt.title('Most Commonly Used Words: %s' % (artist_file), fontsize=24)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pronouncing\n",
    "import markovify\n",
    "import re\n",
    "import random\n",
    "import numpy as np\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM\n",
    "\n",
    "def create_network(depth):\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(LSTM(4, input_shape=(2, 2), return_sequences=True))\n",
    "\tfor i in range(depth):\n",
    "\t\tmodel.add(LSTM(8, return_sequences=True))\n",
    "\tmodel.add(LSTM(2, return_sequences=True))\n",
    "\tmodel.summary()\n",
    "\tmodel.compile(optimizer='rmsprop',\n",
    "              loss='mse')\n",
    "\tif artist + \".rap\" in os.listdir(\".\") and train_mode == False:\n",
    "\t\tmodel.load_weights(str(artist + \".rap\"))\n",
    "\t\tprint(\"loading saved network: \" + str(artist) + \".rap\") \n",
    "\treturn model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def markov(text_file):\n",
    "    ######\n",
    "\tread = open(text_file, \"r\", encoding='utf-8').read()\n",
    "\ttext_model = markovify.NewlineText(read)\n",
    "\treturn text_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def syllables(line):\n",
    "\tcount = 0\n",
    "\tfor word in line.split(\" \"):\n",
    "\t\tvowels = 'aeiouy'\n",
    "# \t\tword = word.lower().strip(\"!@#$%^&*()_+-={}[];:,.<>/?\")\n",
    "\t\tword = word.lower().strip(\".:;?!\")\n",
    "\t\tif len(word) > 0 and word[0] in vowels:\n",
    "\t\t\tcount +=1\n",
    "\t\tfor index in range(1,len(word)):\n",
    "\t\t\tif word[index] in vowels and word[index-1] not in vowels:\n",
    "\t\t\t\tcount +=1\n",
    "\t\tif word.endswith('e'):\n",
    "\t\t\tcount -= 1\n",
    "\t\tif word.endswith('le'):\n",
    "\t\t\tcount+=1\n",
    "\t\tif count == 0:\n",
    "\t\t\tcount +=1\n",
    "\t\t#print(count, maxsyllables)\n",
    "\treturn count / maxsyllables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rhymeindex(lyrics):\n",
    "\tif str(artist) + \".rhymes\" in os.listdir(\".\") and train_mode == False:\n",
    "\t\tprint (\"loading saved rhymes from \" + str(artist) + \".rhymes\")\n",
    "\t\treturn open(str(artist) + \".rhymes\", \"r\",encoding='utf-8').read().split(\"\\n\")\n",
    "\telse:\n",
    "\t\trhyme_master_list = []\n",
    "\t\tprint (\"Building list of rhymes:\")\n",
    "\t\tfor i in lyrics:\n",
    "\t\t\tword = re.sub(r\"\\W+\", '', i.split(\" \")[-1]).lower()\n",
    "\t\t\trhymeslist = pronouncing.rhymes(word)\n",
    "\t\t\trhymeslistends = []      \n",
    "\t\t\tfor i in rhymeslist:\n",
    "\t\t\t\trhymeslistends.append(i[-2:])\n",
    "\t\t\ttry:\n",
    "\t\t\t\trhymescheme = max(set(rhymeslistends), key=rhymeslistends.count)\n",
    "\t\t\texcept Exception:\n",
    "\t\t\t\trhymescheme = word[-2:]\n",
    "\t\t\trhyme_master_list.append(rhymescheme)\n",
    "\t\trhyme_master_list = list(set(rhyme_master_list))\n",
    "\t\treverselist = [x[::-1] for x in rhyme_master_list]\n",
    "\t\treverselist = sorted(reverselist)\n",
    "\t\trhymelist = [x[::-1] for x in reverselist]\n",
    "\t\tprint(\"List of Sorted 2-Letter Rhyme Ends:\")\n",
    "\t\tprint(rhymelist)\n",
    "\t\tf = open(str(artist) + \".rhymes\", \"w\", encoding='utf-8')\n",
    "\t\tf.write(\"\\n\".join(rhymelist))\n",
    "\t\tf.close()\n",
    "\t\treturn rhymelist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rhyme(line, rhyme_list):\n",
    "\tword = re.sub(r\"\\W+\", '', line.split(\" \")[-1]).lower()\n",
    "\trhymeslist = pronouncing.rhymes(word)\n",
    "\trhymeslistends = []\n",
    "\tfor i in rhymeslist:\n",
    "\t\trhymeslistends.append(i[-2:])\n",
    "\ttry:\n",
    "\t\trhymescheme = max(set(rhymeslistends), key=rhymeslistends.count)\n",
    "\texcept Exception:\n",
    "\t\trhymescheme = word[-2:]\n",
    "\ttry:\n",
    "\t\tfloat_rhyme = rhyme_list.index(rhymescheme)\n",
    "\t\tfloat_rhyme = float_rhyme / float(len(rhyme_list))\n",
    "\t\treturn float_rhyme\n",
    "\texcept Exception:\n",
    "\t\tfloat_rhyme = None\n",
    "\t\treturn float_rhyme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_lyrics_file(text_file):\n",
    "\ttext = open(text_file, encoding='utf-8').read()\n",
    "\ttext = text.split(\"\\n\")\n",
    "\twhile \"\" in text:\n",
    "\t\ttext.remove(\"\")\n",
    "\treturn text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_lyrics(text_model, text_file):\n",
    "\tbars = []\n",
    "\tlast_words = []\n",
    "\tlyriclength = len(open(text_file,encoding='utf-8').read().split(\"\\n\"))\n",
    "\tcount = 0\n",
    "\tmarkov_model = markov(text_file)\n",
    "\t\n",
    "\twhile len(bars) < lyriclength / 9 and count < lyriclength * 2:\n",
    "\t\tbar = markov_model.make_sentence(max_overlap_ratio = .49, tries=100)\n",
    "\t\tif type(bar) != type(None) and syllables(bar) < 1:\n",
    "\t\t\tdef get_last_word(bar):\n",
    "\t\t\t\tlast_word = bar.split(\" \")[-1]\n",
    "\t\t\t\tif last_word[-1] in \"!.?,\":\n",
    "\t\t\t\t\tlast_word = last_word[:-1]\n",
    "\t\t\t\treturn last_word\n",
    "\t\t\tlast_word = get_last_word(bar)\n",
    "\t\t\tif bar not in bars and last_words.count(last_word) < 3:\n",
    "\t\t\t\tbars.append(bar)\n",
    "\t\t\t\tlast_words.append(last_word)\n",
    "\t\t\t\tcount += 1\n",
    "\treturn bars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_dataset(lines, rhyme_list):\n",
    "\tdataset = []\n",
    "\tline_list = []\n",
    "\tfor line in lines:\n",
    "\t\tline_list = [line, syllables(line), rhyme(line, rhyme_list)]\n",
    "\t\tdataset.append(line_list)\n",
    "\tx_data = []\n",
    "\ty_data = []\n",
    "\tfor i in range(len(dataset) - 3):\n",
    "\t\tline1 = dataset[i    ][1:]\n",
    "\t\tline2 = dataset[i + 1][1:]\n",
    "\t\tline3 = dataset[i + 2][1:]\n",
    "\t\tline4 = dataset[i + 3][1:]\n",
    "\t\tx = [line1[0], line1[1], line2[0], line2[1]]\n",
    "\t\tx = np.array(x)\n",
    "\t\tx = x.reshape(2,2)\n",
    "\t\tx_data.append(x)\n",
    "\t\ty = [line3[0], line3[1], line4[0], line4[1]]\n",
    "\t\ty = np.array(y)\n",
    "\t\ty = y.reshape(2,2)\n",
    "\t\ty_data.append(y)\n",
    "\tx_data = np.array(x_data)\n",
    "\ty_data = np.array(y_data)\n",
    "\treturn x_data, y_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compose_rap(lines, rhyme_list, lyrics_file, model):\n",
    "\trap_vectors = []\n",
    "\thuman_lyrics = split_lyrics_file(lyrics_file)\n",
    "\tinitial_index = random.choice(range(len(human_lyrics) - 1))\n",
    "\tinitial_lines = human_lyrics[initial_index:initial_index + 2]\n",
    "\tstarting_input = []\n",
    "\tfor line in initial_lines:\n",
    "\t\tstarting_input.append([syllables(line), rhyme(line, rhyme_list)])\n",
    "\tstarting_vectors = model.predict(np.array([starting_input]).flatten().reshape(1, 2, 2))\n",
    "\trap_vectors.append(starting_vectors)\n",
    "\tfor i in range(100):\n",
    "\t\trap_vectors.append(model.predict(np.array([rap_vectors[-1]]).flatten().reshape(1, 2, 2)))\n",
    "\treturn rap_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectors_into_song(vectors, generated_lyrics, rhyme_list):\n",
    "\tprint (\"\\n\\n\")\t\n",
    "\tprint (\"Writing verse:\")\n",
    "\tprint (\"\\n\\n\")\n",
    "\tdef last_word_compare(rap, line2):\n",
    "\t\tpenalty = 0 \n",
    "\t\tfor line1 in rap:\n",
    "\t\t\tword1 = line1.split(\" \")[-1]\n",
    "\t\t\tword2 = line2.split(\" \")[-1]\n",
    "\t\t\twhile word1[-1] in \"?!,. \":\n",
    "\t\t\t\tword1 = word1[:-1]\n",
    "\t\t\twhile word2[-1] in \"?!,. \":\n",
    "\t\t\t\tword2 = word2[:-1]\n",
    "\t\t\tif word1 == word2:\n",
    "\t\t\t\tpenalty += 0.2\n",
    "\t\treturn penalty\n",
    "\tdef calculate_score(vector_half, syllables, rhyme, penalty):\n",
    "\t\tdesired_syllables = vector_half[0]\n",
    "\t\tdesired_rhyme = vector_half[1]\n",
    "\t\tdesired_syllables = desired_syllables * maxsyllables\n",
    "\t\tdesired_rhyme = desired_rhyme * len(rhyme_list)\n",
    "\t\tscore = 1.0 - abs(float(desired_syllables) - float(syllables)) + abs(float(desired_rhyme) - float(rhyme)) - penalty\n",
    "\t\treturn score\n",
    "\tdataset = []\n",
    "\tfor line in generated_lyrics:\n",
    "\t\tline_list = [line, syllables(line), rhyme(line, rhyme_list)]\n",
    "\t\tdataset.append(line_list)\n",
    "\trap = []\n",
    "\tvector_halves = []\n",
    "\tfor vector in vectors:\n",
    "\t\tvector_halves.append(list(vector[0][0])) \n",
    "\t\tvector_halves.append(list(vector[0][1]))\n",
    "\tfor vector in vector_halves:\n",
    "\t\tscorelist = []\n",
    "\t\tfor item in dataset:\n",
    "\t\t\tline = item[0]\n",
    "\t\t\tif len(rap) != 0:\n",
    "\t\t\t\tpenalty = last_word_compare(rap, line)\n",
    "\t\t\telse:\n",
    "\t\t\t\tpenalty = 0\n",
    "\t\t\ttotal_score = calculate_score(vector, item[1], item[2], penalty)\n",
    "\t\t\tscore_entry = [line, total_score]\n",
    "\t\t\tscorelist.append(score_entry)\n",
    "\t\tfixed_score_list = [0]\n",
    "\t\tfor score in scorelist:\n",
    "\t\t\tfixed_score_list.append(float(score[1]))\n",
    "\t\tmax_score = max(fixed_score_list)\n",
    "\t\tfor item in scorelist:\n",
    "\t\t\tif item[1] == max_score:\n",
    "\t\t\t\trap.append(item[0])\n",
    "\t\t\t\tprint (str(item[0]))\n",
    "\t\t\t\tfor i in dataset:\n",
    "\t\t\t\t\tif item[0] == i[0]:\n",
    "\t\t\t\t\t\tdataset.remove(i)\n",
    "\t\t\t\t\t\tbreak\n",
    "\t\t\t\tbreak     \n",
    "\treturn rap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(depth, train_mode):\n",
    "\tmodel = create_network(depth)\n",
    "\ttext_model = markov(text_file)\n",
    "\tif train_mode == True:\n",
    "\t\tbars = split_lyrics_file(text_file)\n",
    "\tif train_mode == False:\n",
    "\t\tbars = generate_lyrics(text_model, text_file)\n",
    "\trhyme_list = rhymeindex(bars)\n",
    "\tif train_mode == True:\n",
    "\t\tx_data, y_data = build_dataset(bars, rhyme_list)\n",
    "\t\ttrain(x_data, y_data, model)\n",
    "\tif train_mode == False:\n",
    "\t\tvectors = compose_rap(bars, rhyme_list, text_file, model)\n",
    "\t\trap = vectors_into_song(vectors, bars, rhyme_list)\n",
    "\t\tf = open(rap_file, \"w\", encoding='utf-8')\n",
    "\t\tfor bar in rap:\n",
    "\t\t\tf.write(bar)\n",
    "\t\t\tf.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "depth = 4 \n",
    "maxsyllables = 10\n",
    "artist = \"artist\"\n",
    "rap_file = \"temporary_poem.txt\"\n",
    "maxsyllables = 8\n",
    "\n",
    "filenames = ['../input/poetry/Lil_Wayne.txt', '../input/poetry/bieber.txt']\n",
    "with open('combined.txt', 'w') as outfile:\n",
    "    for fname in filenames:\n",
    "        with open(fname) as infile:\n",
    "            for line in infile:\n",
    "                outfile.write(line)\n",
    "                \n",
    "                \n",
    "text_file = \"combined.txt\"\n",
    "train_mode = True        \n",
    "main(depth, train_mode)\n",
    "train_mode = False\n",
    "main(depth, train_mode)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
